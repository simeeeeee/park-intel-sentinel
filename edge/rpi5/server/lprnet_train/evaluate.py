import torch
import torch.nn as nn  # <<< ë¹ ì¡Œë˜ í•µì‹¬ import ë¬¸
import torch.nn.functional as F
import numpy as np
import cv2
import argparse
import os
from imutils import paths
from tqdm import tqdm

# =================================================================================
# 1. ëª¨ë¸ ë° ìƒìˆ˜ ì •ì˜ (í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•˜ê²Œ ìœ ì§€)
# =================================================================================
# ì´ ë¶€ë¶„ì€ .pt íŒŒì¼(ëª¨ë¸ êµ¬ì¡° í¬í•¨)ì„ ì˜¬ë°”ë¥´ê²Œ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•´ ë°˜ë“œì‹œ í•„ìš”í•©ë‹ˆë‹¤.

CHARS = [
    'ê°€', 'ë‚˜', 'ë‹¤', 'ë¼', 'ë§ˆ', 'ê±°', 'ë„ˆ', 'ë”', 'ëŸ¬', 'ë¨¸', 'ë²„', 'ì„œ', 'ì–´', 'ì €',
    'ê³ ', 'ë…¸', 'ë„', 'ë¡œ', 'ëª¨', 'ë³´', 'ì†Œ', 'ì˜¤', 'ì¡°',
    'êµ¬', 'ëˆ„', 'ë‘', 'ë£¨', 'ë¬´', 'ë¶€', 'ìˆ˜', 'ìš°', 'ì£¼',
    'ì•„', 'ë°”', 'ì‚¬', 'ì', 'ë°°', 'í—ˆ', 'í•˜', 'í˜¸', 'êµ­',
    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-'
]

class small_basic_block(nn.Module):
    def __init__(self, ch_in, ch_out):
        super(small_basic_block, self).__init__()
        self.block = nn.Sequential(
            nn.Conv2d(ch_in, ch_out // 4, kernel_size=1), nn.ReLU(),
            nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(3, 1), padding=(1, 0)), nn.ReLU(),
            nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(1, 3), padding=(0, 1)), nn.ReLU(),
            nn.Conv2d(ch_out // 4, ch_out, kernel_size=1),
        )
    def forward(self, x): return self.block(x)

class LPRNet_Hailo(nn.Module):
    def __init__(self, lpr_max_len, class_num, dropout_rate):
        super(LPRNet_Hailo, self).__init__()
        self.lpr_max_len = lpr_max_len; self.class_num = class_num
        self.backbone = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(64), nn.ReLU(),
            nn.MaxPool2d(kernel_size=3, stride=(3, 5)), 
            small_basic_block(64, 128), nn.BatchNorm2d(128), nn.ReLU(),
            nn.MaxPool2d(kernel_size=3, stride=(2, 3)),
            small_basic_block(128, 256), nn.BatchNorm2d(256), nn.ReLU(),
            small_basic_block(256, 256), nn.BatchNorm2d(256), nn.ReLU(),
            nn.MaxPool2d(kernel_size=(4, 2), stride=(2, 1)),
            nn.Dropout(dropout_rate),
            nn.Conv2d(256, 256, kernel_size=(4, 1), stride=1), nn.BatchNorm2d(256), nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Conv2d(256, len(CHARS), kernel_size=(1, 13), stride=1, padding=(0, 6)),
        )
    def forward(self, x): return self.backbone(x)

# =================================================================================
# 2. í‰ê°€ ë¡œì§ (ì´í•˜ ì½”ë“œëŠ” ë³€ê²½ ì—†ìŒ)
# =================================================================================

def ctc_greedy_decode(logits):
    """
    Greedy CTC ë””ì½”ë”. ëª¨ë¸ì˜ ë¡œì§“ ì¶œë ¥ì„ ìµœì¢… í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    Args:
        logits (torch.Tensor): ëª¨ë¸ì˜ ë¡œì§“ ì¶œë ¥ (Width, Num_Classes)
    """
    best_path = torch.argmax(logits, dim=1)
    blank_idx = len(CHARS) - 1
    
    # 1. ì—°ì†ëœ ì¤‘ë³µ ë¬¸ì ì œê±°
    collapsed_indices = []
    prev_idx = -1
    for idx in best_path:
        if idx.item() != prev_idx:
            collapsed_indices.append(idx.item())
        prev_idx = idx.item()
        
    # 2. 'blank' í† í° ì œê±°
    final_text = "".join([CHARS[idx] for idx in collapsed_indices if idx != blank_idx])
            
    return final_text

def evaluate_model(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    print(f"Loading model from {args.model_path}...")
    try:
        model = torch.load(args.model_path, map_location=device, weights_only=False)
        print("âœ… Model loaded successfully.")
    except Exception as e:
        print(f"âŒ Error loading model: {e}")
        return

    model.eval()

    image_paths = list(paths.list_images(args.data_dir))
    if not image_paths:
        print(f"âŒ No images found in directory: {args.data_dir}")
        return
        
    print(f"Found {len(image_paths)} images. Starting evaluation...")

    correct_count = 0
    incorrect_examples = []

    for image_path in tqdm(image_paths, desc="Evaluating"):
        basename = os.path.basename(image_path)
        
        # <<< ìˆ˜ì •ëœ ë¶€ë¶„: íŒŒì¼ í™•ì¥ìë¥¼ ë¨¼ì € ì œê±°í•©ë‹ˆë‹¤. >>>
        imgname, _ = os.path.splitext(basename)
        ground_truth = imgname.split("-")[0].split("_")[0]
        # ---------------------------------------------

        img = cv2.imread(image_path)
        # ... (ì´í•˜ ì½”ë“œëŠ” ë³€ê²½ ì—†ìŒ) ...
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (args.img_width, args.img_height))
        img = img.astype('float32')
        img -= 127.5
        img *= 0.0078125
        img = np.transpose(img, (2, 0, 1))
        
        img_tensor = torch.from_numpy(img).unsqueeze(0).to(device)

        with torch.no_grad():
            logits_map = model(img_tensor)
            logits_seq = torch.mean(logits_map, dim=2)
            logits_for_decode = logits_seq.permute(2, 0, 1).squeeze(1)
            predicted_text = ctc_greedy_decode(logits_for_decode)
        
        if predicted_text == ground_truth:
            correct_count += 1
        else:
            if len(incorrect_examples) < 10:
                incorrect_examples.append(f"  - File: {basename} | GT: '{ground_truth}' | Pred: '{predicted_text}'")

    # 6. ìµœì¢… ê²°ê³¼ ì¶œë ¥
    total_images = len(image_paths)
    accuracy = (correct_count / total_images) * 100 if total_images > 0 else 0

    print("\n--- ğŸ“Š Evaluation Results ---")
    print(f"Total Images:    {total_images}")
    print(f"Correct:         {correct_count}")
    print(f"Incorrect:       {total_images - correct_count}")
    print(f"Accuracy:        {accuracy:.2f}%")
    print("----------------------------")
    
    if accuracy > 95:
        print("ğŸ† Excellent performance!")
    elif accuracy > 90:
        print("ğŸ‘ Good performance.")
    elif accuracy > 80:
        print("ğŸ™‚ Decent performance, but could be improved.")
    else:
        print("ğŸ¤” Needs more training or data augmentation.")

    if incorrect_examples:
        print("\nğŸ“ Examples of Incorrect Predictions:")
        for example in incorrect_examples:
            print(example)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="Evaluate LPRNet model performance")
    parser.add_argument('--model_path', type=str, required=True, help='Path to the trained model .pt file')
    parser.add_argument('--data_dir', type=str, required=True, help='Path to the evaluation data directory')
    # ëª¨ë¸ í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ì´ë¯¸ì§€ í¬ê¸°ì™€ ë™ì¼í•˜ê²Œ ì„¤ì •
    parser.add_argument('--img_width', type=int, default=300, help='Image width for resize')
    parser.add_argument('--img_height', type=int, default=75, help='Image height for resize')
    
    args = parser.parse_args()
    evaluate_model(args)