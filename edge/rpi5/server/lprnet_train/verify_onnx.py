import onnxruntime as ort
import numpy as np
import cv2
import argparse
import os
from imutils import paths
from tqdm import tqdm

# --- 1. ìƒìˆ˜ ë° ì „/í›„ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜ (HEF í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼) ---
LPR_CHARACTERS = [
    'ê°€', 'ë‚˜', 'ë‹¤', 'ë¼', 'ë§ˆ', 'ê±°', 'ë„ˆ', 'ë”', 'ëŸ¬', 'ë¨¸', 'ë²„', 'ì„œ', 'ì–´', 'ì €',
    'ê³ ', 'ë…¸', 'ë„', 'ë¡œ', 'ëª¨', 'ë³´', 'ì†Œ', 'ì˜¤', 'ì¡°',
    'êµ¬', 'ëˆ„', 'ë‘', 'ë£¨', 'ë¬´', 'ë¶€', 'ìˆ˜', 'ìš°', 'ì£¼',
    'ì•„', 'ë°”', 'ì‚¬', 'ìž', 'ë°°', 'í—ˆ', 'í•˜', 'í˜¸', 'êµ­',
    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-'
]

def preprocess_lpr_image(image, input_shape):
    # input_shape: (height, width)
    input_h, input_w = input_shape
    resized_img = cv2.resize(image, (input_w, input_h), interpolation=cv2.INTER_LINEAR)
    rgb_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)
    # ì •ê·œí™” í›„ ì±„ë„ ìˆœì„œ ë³€ê²½ (H, W, C) -> (C, H, W)
    normalized_img = (rgb_img.astype(np.float32) - 127.5) * 0.0078125
    transposed_img = np.transpose(normalized_img, (2, 0, 1))
    # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
    return np.expand_dims(transposed_img, axis=0)

def ctc_greedy_decode(raw_logits, characters):
    # ONNX Runtime ì¶œë ¥ì€ (Batch, C, H, W) -> ì˜ˆ: (1, 52, 5, 19)
    logits_map = np.squeeze(raw_logits, axis=0) # (C, H, W)
    # (C, H, W) -> (H, W, C) -> (W, C)
    logits_seq = np.mean(np.transpose(logits_map, (1, 2, 0)), axis=0)
    
    best_path_indices = np.argmax(logits_seq, axis=1)
    blank_idx = len(characters) - 1
    decoded_indices = []
    prev_idx = -1
    for idx in best_path_indices:
        if idx != prev_idx:
            if idx != blank_idx:
                decoded_indices.append(idx)
        prev_idx = idx
    final_text = "".join([characters[i] for i in decoded_indices])
    return final_text

# --- 2. ONNX ëª¨ë¸ í‰ê°€ ë©”ì¸ í•¨ìˆ˜ ---
def verify_onnx_model(args):
    print(f"[SETUP] Loading ONNX model from {args.onnx_path}...")
    try:
        # ONNX Runtime ì„¸ì…˜ ìƒì„±
        session = ort.InferenceSession(args.onnx_path, providers=['CPUExecutionProvider'])
        print("âœ… ONNX model loaded successfully.")
    except Exception as e:
        print(f"âŒ Error loading ONNX model: {e}")
        return

    # ëª¨ë¸ì˜ ìž…ë ¥/ì¶œë ¥ ì´ë¦„ ìžë™ ê°ì§€
    input_name = session.get_inputs()[0].name
    output_name = session.get_outputs()[0].name
    # ONNXëŠ” (Batch, C, H, W) ìˆœì„œì´ë¯€ë¡œ, H, Wë¥¼ ê°€ì ¸ì˜´
    _, _, input_h, input_w = session.get_inputs()[0].shape

    image_paths = list(paths.list_images(args.data_dir))
    if not image_paths:
        print(f"âŒ No images found in directory: {args.data_dir}")
        return
        
    print(f"Found {len(image_paths)} images. Starting verification...")

    correct_count = 0
    
    for image_path in tqdm(image_paths, desc="Verifying ONNX model"):
        # íŒŒì¼ëª…ì—ì„œ ì •ë‹µ ì¶”ì¶œ
        basename = os.path.basename(image_path)
        imgname, _ = os.path.splitext(basename)
        ground_truth = imgname.split("-")[0].split("_")[0]
        
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
        image = cv2.imread(image_path)
        input_tensor = preprocess_lpr_image(image, (input_h, input_w))
        
        # ONNX Runtimeìœ¼ë¡œ ì¶”ë¡  ì‹¤í–‰
        raw_logits_map = session.run([output_name], {input_name: input_tensor})[0]
        
        # í›„ì²˜ë¦¬ (ë””ì½”ë”©) ë° ë¹„êµ
        predicted_text = ctc_greedy_decode(raw_logits_map, LPR_CHARACTERS)
        if predicted_text == ground_truth:
            correct_count += 1

    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    total_images = len(image_paths)
    accuracy = (correct_count / total_images) * 100 if total_images > 0 else 0
    print("\n--- ðŸ“Š ONNX Model Verification Results ---")
    print(f"Total Images:    {total_images}")
    print(f"Correct:         {correct_count}")
    print(f"Accuracy:        {accuracy:.2f}%")
    print("------------------------------------------")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="Verify LPRNet ONNX model performance")
    parser.add_argument('--onnx_path', type=str, required=True, help='Path to the LPRNet .onnx file')
    parser.add_argument('--data_dir', type=str, required=True, help='Path to the evaluation data directory (e.g., ./data)')
    
    args = parser.parse_args()
    verify_onnx_model(args)